\documentclass{article}

% *** CITATION PACKAGES *** 

\usepackage{cite}

% *** GRAPHICS RELATED PACKAGES *** 

\usepackage[pdftex]{graphicx}
\usepackage{epstopdf}
\usepackage{tikz}

% *** MATH PACKAGES ***

\usepackage{amsmath} 
\usepackage{amssymb} 
\usepackage{amsthm}
\usepackage{latexsym} 
\usepackage{amstext}
\usepackage{amsxtra} 
\usepackage{amsfonts} 
\usepackage{graphicx}


\usepackage{algorithmic}
\usepackage{algorithm}

\usepackage{url}

% *** ALIGNMENT PACKAGES *** 


\usepackage{array} 
\usepackage{mdwmath}
\usepackage{mdwtab} 

\usepackage[tight,footnotesize,caption=false]{subfig}

% *** CITATION PACKAGE *** %
% ** IJRR asks for an author-date bibtex style ** %
\usepackage{harvard}


\newtheorem{theorem}{Theorem}
\renewcommand{\labelitemi}{$-$}
\newcommand\manifold{\mathcal{M}}
\newcommand\goalmanifold{\mathcal{M}_{g}}

\begin{document}

\title{Dynamic Walking and Whole-Body Motion Planning for Humanoid Robots: an Integrated Approach}

\author{
  S\'ebastien Dalibard\and
  Antonio El Khoury\and
  Florent Lamiraux\and
  Alireza Nakhaei\and
  Michel Ta\"ix\and
  Jean-Paul Laumond
  \footnote{The authors are with CNRS ; LAAS ; 7 avenue du colonel Roche, F-31077
    Toulouse Cedex 4, France and Universit\'e de Toulouse ; UPS, INSA, INP, ISAE ;
    UT1, UTM, LAAS ; F-31077 Toulouse
    Cedex 4, France. S\'ebastien Dalibard is now with Nanyang Technological University, Singapore.}
  \footnote{
    This paper summarizes and extends previous work that appeared in the 9th and 11th
    IEEE-RAS International Conference on Humanoid Robots, 2009 and 2011.
  }
}

\date{}

\maketitle

\begin{abstract}

This paper presents a general method for planning collision-free whole-body walking motions
for humanoid robots. First, we present a randomized algorithm for constrained motion
planning, that is used to generate collision-free statically balanced paths solving
manipulation tasks. Then, we show that dynamic walking makes humanoid robots 
small-space controllable. Such a property allows to easily transform 
collision-free statically balanced paths into 
collision-free dynamically balanced trajectories. It leads to a sound 
algorithm which has been applied and evaluated on several
problems where whole-body planning and  walk are needed,
and the results have been validated  on a real HRP-2 robot.

\end{abstract}

\section{Introduction}

During the last twenty years, impressive progress has been achieved in humanoid
robot hardware and control. This leads to a rising need for software and algorithms
improving the usability and autonomy of those robots. One important area of research
focuses on the development of robust and general motion generation techniques for safe
and autonomous operation in human environments, such as offices or homes.

Motion planning for humanoid robots is challenging for several reasons. First,
the computational complexity of classic motion planning algorithms is exponential
in the number of Degrees of Freedom (DoFs) of the considered system, which is
high for humanoid kinematic trees. Second, a humanoid robot is an under-actuated system:
the DoFs that control the position and orientation of the whole robot in space
are not directly controlled, they derive from the articular DoFs of the robot legs.
Those latter should be controlled with care to guarantee dynamically balanced motions,
for manipulation or navigation.

When planning collision free motions for humanoid robots, different representations
of the robot and its environment can be used. The choice of the level of details of
the representation indicates the difficulty of the considered problem. The simplest
option consists in considering the robot as a navigating 2D shape, and computing 
obstacle avoidance in a planar model of the world. Another possibility is to 
compute only collision-free footsteps. 
In complex and difficult environments, such as the one presented in Fig.~\ref{fig:couv},
it can be necessary to consider exact 3D models of a humanoid robot and its environment.


\begin{figure}[h]
\centering
\includegraphics[width=0.6\linewidth]{pics/chairs/couv.png}
\caption{The robot HRP-2 passing between two chairs. In this kind of
  environment whole-body collision avoidance is needed during
  locomotion.} 
\label{fig:couv}
\end{figure}

There are two main ways of using motion planners to generate dynamically balanced robotic motions.
The more general one is to plan in a robot dynamic space. By taking into account both robot
configuration and velocity, motions that satisfy dynamic balance constraints can be generated
at a planning phase. When planning motion for humanoid robots, this is a particularly costly
approach, as the size of the space to explore is augmented with the robot velocity and footstep
positions. The other way is to first plan  a geometric path that can be approximated by a
dynamic trajectory in a second step. The approach we present in this paper falls into the second 
category. Some feasible dynamic motions are inherently impossible to compute with this kind
of approach. For example, jumping motions cannot be generated by a purely geometric planner.

\textbf{In this paper, we present a planning algorithm that considers exact models of a humanoid
robot and its environment. It is used to solve navigation and manipulation problems. Our planner 
generates collision-free, statically balanced
geometric paths, i.e. paths such that for any path configurations, the robot is balanced on its
feet with zero speed. We also present a constructive formal proof that these paths can be
approximated by collision-free, dynamically balanced walk trajectories, i.e. trajectories such
that for any trajectory instant, the robot is balanced on at least one foot. Our planner is designed for perfectly modeled indoor
environments, where the floor is horizontal and flat. Also, because we do not compute explicitly footstep
positions at the planning stage, the presented planner is unable to plan motions in which the
robot steps over obstacles. These limitations are discussed in the paper.}


\subsection{Outline}
Section~\ref{sec:related} reviews the related work and states our contribution. 
Section~\ref{sec:wb} presents a constrained motion planning algorithm, and its
use on a humanoid robot manipulation problem. Section~\ref{sec:wb-step} generalizes
the previous algorithm to problems that require locomotion. The generalization is
well-grounded, and
based on a controllability property of legged robots demonstrated in the paper. 
Section~\ref{sec:exp} presents some experimental results, and 
Section~\ref{sec:limits} discusses the limitations and potential future work of our
method.


\section{Related Work and Contribution}
\label{sec:related}


This work is based on several fields of humanoid robotics
research: prioritized inverse kinematics, randomized  whole-body  motion
planning and walk pattern generators based on the Zero-Moment
Point (ZMP) formalism. This section summarizes the literature related to each of 
these fields.

\subsection{Prioritized Inverse Kinematics}

The problem of inverse kinematics for a humanoid robot, or any articulated
structure, is to compute a joint position to achieve an end-effector pose. As the
robots we deal with are redundant, it is natural to take advantage of
this redundancy by specifying multiple tasks, potentially with
different priorities. This problem has been widely studied in robotics
planning and control literature, and many Jacobian-based solutions have been
proposed, among which 
\cite{nakamura1986iks}, \cite{siciliano1991gfm},
\cite{baerlocher1998tpf} and \cite{khatib2004wbd}.
Obstacle avoidance can be taken into account with similar methods. To
do so, one has to include the obstacles as  constraints to
satisfy, see for example \cite{kanehiro2008lca}.
These methods are prone to fall into local minima, thus global motion
planning is needed to overcome this limitation.
\cite{TouGieGoe2007} propose a motion generation method where tasks follow
trajectories defined by cubic B-splines. The whole-body motion is optimized
with respect to the control point positions. This method can take into account
collisions with simple obstacles.

\subsection{Whole-Body Motion Planning}

When  planning a  whole-body motion  for a  humanoid robot, one difficult
challenge is to cope with  the curse of dimensionality. The complexity
of   motion  planning  is   exponential  in   the  dimension   of  the
configuration  space ($\mathcal{C}$)  to explore.  When  dealing with
high-dimensional configuration  spaces, it is  typically impossible to
explicitly represent  them, leading to the use  of randomized sampling
techniques  to solve  global planning  problems. In  the  past fifteen
years,  \textit{Probabilistic Roadmaps} \cite{kavraki1996prp} and  
\textit{Rapidly exploring Random  Trees} (RRT) 
\cite{kuffner00rrtconnect}  have been  developed and  used to  solve many
high-dimensional   planning  problems, see \cite{Lav06} and \cite{choset2005prm} for comprehensive
overviews.
When  using  sampling  techniques  on  a humanoid  robot,  another difficulty
is to  take into  account balance  constraints,  i.e. to
generate  random  configurations   on  zero  volume  submanifolds  of
$\mathcal{C}$. This problem has been investigated with success during
the last few years, \cite{Berenson15032011} presents an exhaustive survey
of Jacobian-based methods. Other recent contributions \cite{porta2012randomized}
present sophisticated constrained motion planning techniques based on higher-dimensional
continuation. Section \ref{sec:wb} presents a simple adaptation
of the RRT algorithm to constrained motion planning, that was first
introduced in \cite{dalibard09}.

\subsection{Walk Pattern Generation}

Another  field of  humanoid  robotics research  is  the generation  of
dynamically balanced walk patterns. Since  the introduction of  the ZMP
formalism  \cite{vukobratovic1969contribution},  several  methods  have  been  proposed  to
generate  walking  motions efficiently.   One  way  to  deal with  the
complexity  of a  humanoid  robot  kinematic tree  is  to use  the
so-called "cart-table" simplified model \cite{kajita2003biped}. Based on this
model,  planning a trajectory  for the  ZMP is  reduced to  planning a
trajectory  for  the Center  of  Mass (CoM)  of  the  robot.  Given  a
trajectory  of  the CoM  and  footprint  positions, inverse  kinematics
solvers can animate  the whole set of DoFs of the
robot to generate a dynamically balanced walk trajectory.


\subsection{Collision-Free Walk Planning}

Collision-free  locomotion   trajectories  are  usually   obtained  by
simplifying the model of either the  robot or the environment. By reducing 
a  humanoid robot to a bounding volume that wraps the swaying motion,
one can  use a simple  planar motion planner  on this bounding  volume and
generate  a valid  locomotion  trajectory. This  strategy  is used  in
\cite{pettre20032} in a computer animation context. Variants of this method
include  dynamic path reshaping  \cite{yoshida-humanoids05}: if  collisions appear
when animating  the locomotion  trajectory, it is  locally reshaped
and re-animated.  This two-stage  strategy does not guarantee that the
locomotion trajectory can be followed or that the local reshaping will
converge.

\textbf{One possible simplification of the environment consists in
  considering obstacles at a footstep level only.
  \cite{kuffner2001footstep,chestnutt2005footstep,kuffner2005motion}
  use an A$^{*}$ algorithm to find collision-free footsteps.}  In
\cite{perrin2012fast}, the authors compute dynamic walking motions
avoiding collisions at the leg level by using an RRT algorithm.

Some planning methods for free-climbing robots \cite{bretl2006motion}
can be seen as a general way 
to consider quasi-static multi-step planning. They are not however directly applicable to
humanoid dynamically balanced locomotion.
Other recent contributions to the field of locomotion planning  include algorithms 
considering the dynamics at the planning phase \cite{shkolnik2011bounding}. This leads to 
a growth of algorithmic complexity, particularly costly for high-dimensional
systems such as humanoid robots. To the authors knowledge such techniques have not been
used on humanoid robotic platforms so far.

\textbf{In this work, we show that, under some assumptions, it is
  sufficient to plan in the configuration space in a first step, even
  though the final output of our algorithm is guaranteed to be a
  dynamically balanced walk motion. This result was first presented in
  \cite{dalibard2011small}.}

\subsection{Contribution}

The main contribution of this work is a whole-body motion planner for
humanoid robots that computes collision-free walking trajectories,
based on exact models of both robot and environment. It is used to
solve manipulation tasks that may require walking. The first stage of
our algorithm uses a sampling-based constrained motion planner and
computes a collision-free statically balanced path for a robot which
can be fixed or sliding on the ground.

Another contribution of this paper is the formal proof that this first
path can always be approximated by a dynamically balanced,
collision-free walking trajectory. We have implemented this
well-grounded method, and the results have been validated on the HRP-2
robot.

\section{Randomized Motion Planning on Constraint Manifolds}
\label{sec:wb}

\textbf{This section presents an algorithm for constrained motion
  planning in the configuration space $\mathcal{C}$. In the particular
  case of a humanoid robot which is an under-actuated system,
  $\mathcal{C}=\mathcal{Q} \times SE(3)$, where $\mathcal{Q}$
  represents the kinematic tree actuators and $SE(3)$ corresponds to a
  fictitious floating joint attached to the root of the tree. If the
  robot has $n$ actuated DoFs, then $dim(\mathcal{Q})=n$ and
  $dim(\mathcal{C})=n+6$. A configuration $q$ of $\mathcal{C}$ is said
  to be valid iff, besides being collision-free, it lies on a specific
  submanifold $\manifold$ of $\mathcal{C}$. $\manifold$ is called
  the planning submanifold.}

The problem solved here differs from classic approaches in two ways:
\begin{enumerate}
\item the set of valid configurations is defined implicitly, as the
  set of collision-free configurations satisfying a given set of
  inverse kinematics balance constraints;
\item the goal submanifold $\goalmanifold$ is also defined implicitly,
  by additional inverse kinematics constraints.
\end{enumerate}
During global planning, we will consider several types of
tasks and constraints for various reasons:
\begin{itemize}
\item Static balance: the CoM of the robot stays above
  the support polygon center, the two feet have fixed position and
  orientation.
\item End-effector position and orientation: the goals of some problems presented
  in the experimental section of this paper are defined as a specific robot hand pose,
  or a gaze direction.
\item Configuration task: our adaptation of randomized motion planning algorithms 
  uses tasks defined as the distance towards a given configuration in $\mathcal{C}$. 
  This will be detailed in the following section.
\end{itemize}


Our algorithm generalizes randomized tree expansion strategies, introduced in both \cite{HsuLat99c} and
\cite{kuffner00rrtconnect} to constrained motion planning problems. Next subsection will recall the structure of the RRT algorithm,
a popular randomized motion planning algorithm.


\subsection{Rapidly exploring Random Trees (RRT)}

The classic RRT algorithm, as presented in  \cite{kuffner00rrtconnect}, grows 
a random tree inside the robot 
collision-free configuration space 
$\mathcal{C}_{free}$. Each iteration of the algorithm attempts to extend the tree
by adding new vertices in the direction of a randomly selected configuration
$q_{rand}$. Algorithm~\ref{algRRT} shows the pseudo-code of the RRT algorithm.
It takes as input an initial configuration $q_0$ and grows a tree  $\mathcal{T}$ rooted 
in $q_0$. 

\begin{algorithm}
\caption{RRT($q_0$)}
\label{algRRT}
\begin{algorithmic}
\STATE $\mathcal{T}.$Init$(q_0)$
\FOR{$i$ = 1 to $K$}
\STATE $q_{rand} \leftarrow $ Rand$(\mathcal{C})$
\STATE $q_{near} \leftarrow $ Nearest$(q_{rand},\mathcal{T})$
\STATE Extend$(\mathcal{T},q_{near},q_{rand})$
\ENDFOR

\end{algorithmic}
\end{algorithm}

One way to make the RRT algorithm more efficient is to grow trees from both the initial
and  goal configurations. This was first proposed in 
\cite{kuffner00rrtconnect}. Our formulation of manipulation planning does
not include an explicit goal configuration, so it is not possible to directly grow
a tree from the goal. To make use of the idea of growing multiple trees, we first
randomly sample the goal submanifold and generate several goal configurations. Then, 
we grow random
trees from the initial configuration and the random goal configurations. The idea of
generating several goals for manipulation planning was proposed in \cite{diankov2008bpc}.

Section~\ref{sec:constraint-solver} describes a constraint solver,
Section~\ref{sec:goal-sampling} the goal manifold sampling, and
Section~\ref{sec:extension} the adaptation or RRT random extensions to
constrained motion planning.

\subsection{Multiple Constraints Solver}
\label{sec:constraint-solver}

\textbf{We show here how a multiple constraints solver works: its
  purpose is to find the root $q$ of a non-linear $C^1$ function
  $f(q)$ with a tolerance of $\varepsilon$. If we want to find a
  configuration on a manifold $\manifold$, $f(q)$ can be defined as a
  vector function that contains the concatenation of all constraints
  defining $\manifold$. Note that as the intersection of two or more
  manifolds is also a manifold, this multi-constraint solver allows us
  also to generate configurations that lie at the intersection of
  several manifolds.}

\textbf{In Algorithm~\ref{algo:newton} a Newton-Raphson method
  \cite{bonnans2006numerical}: starting from an initial value of $q$,
  $q$ is updated iteratively by $- \alpha \left(\frac{\partial
    f}{\partial q}(q)\right)^{+} f(q)$, where $\alpha$ denotes a gain
  and $\left(\frac{\partial f}{\partial q}(q)\right)^{+}$ denotes the
  Moore-Penrose pseudo-inverse of the Jacobian of $f(q)$. The use of
  an adaptive gain $\alpha$ that increases iteratively from an initial
  value $\alpha$ to a maximum value $\alpha_{max}$ has proven to avoid
  overshoots and accelerate convergence. The update rule relies on a
  real factor $w \in [0,1]$; the greater $w$ is, the faster $\alpha$
  will reach $\alpha_{max}$. Obviously, the solver convergence depends
  of the initial value of $q$, and a bad initialization can lead to
  either slow convergence or failure. A cutoff number of iterations
  $it_{max}$ is hence introduced to bypass these cases.}

\textbf{In this work, we observed that values of
  $\varepsilon=10^{-6}$, $\alpha=0.1$, $\alpha_{max}=0.95$ and $w=0.8$
  lead to good behavior, i.e. fast convergence and low failure rate.}

\begin{algorithm}
\caption{\texttt{constraint-solver}($q$, f, $\varepsilon$): find $q$ such that $f(q) = 0$}
\label{algo:newton}
\begin{algorithmic}
\STATE $i=0$
\WHILE{$\|f(q)\| > \varepsilon$ and $i\leq it_{max}$}
\STATE {\color{red} // $\left(.\right)^{+}$ denotes the Moore-Penrose pseudo-inverse}
\STATE $q \leftarrow$ $q - \alpha \left(\frac{\partial f}{\partial q}(q)\right)^{+} f(q)$
\STATE $i$ $\leftarrow$ $i+1$
\STATE {\color{red}// Make $\alpha$ tend toward $\alpha_{max}$}
\STATE $\alpha \rightarrow \alpha_{max} - w(\alpha_{max} - \alpha)$
\ENDWHILE
\IF {$\|f(q)\| \leq \varepsilon$}
\STATE return $q$
\ELSE
\STATE return failure
\ENDIF
\end{algorithmic}
\end{algorithm}

\subsection{Goal Manifold Sampling}
\label{sec:goal-sampling}

The way we generate a goal configuration is the following:
\begin{enumerate}
\item \textbf{Shoot a random configuration $q_{rand}$ in $\mathcal{C}$ with
  uniform distribution.}
\item \textbf{Call \textit{constraint-solver}
  (Algorithm~\ref{algo:newton}) on $q_{rand}$, with $f(q)$ defined by
  the intersection of the planning and goal manifolds $\manifold \cap
  \goalmanifold$.}
\item If success, check for collisions.
\end{enumerate}

\textbf{Fig.~\ref{fig:goal} shows resulting random configurations
  enforcing balance ($\manifold$) and reaching ($\goalmanifold$)
  constraints for the HRP-2 robot.}

\begin{figure}[h]
\centerline {
\includegraphics[width=.24\linewidth]{pics/goal-config/goal0.png}
\includegraphics[width=.24\linewidth]{pics/goal-config/goal1.png}
\includegraphics[width=.24\linewidth]{pics/goal-config/goal2.png}
\includegraphics[width=.24\linewidth]{pics/goal-config/goal3.png}
}

\caption{Random goal configurations solving a reaching task. All the
  configurations are balanced and collision-free, and the right hand of the character
  reaches the orange ball. Note that the ball is also an obstacle.}
\label{fig:goal}
\end{figure}



\subsection{Random Extensions on a Constrained Manifold}
\label{sec:extension}



Fig.~\ref{fig:rrt-extend} shows an extension of the classic 
RRT algorithm, from a configuration already in the tree $q_{near}$ towards a random
configuration $q_{rand}$.

\begin{figure}[h]
  \centering

  \begin{tikzpicture}[x=0.45cm,y=0.45cm]

    \node [draw,circle,inner sep=2pt] (0) at (0,0) {};
    \node [draw,circle,inner sep=2pt] (1) at (1,1) {};
    \node [draw,circle,inner sep=2pt] (2) at (2.4,1) {};
    \node [draw,circle,inner sep=2pt,fill=gray] (qn) at (3.4,2) {};
    \node [above left] at (qn) {$q_{near}$};
    \node (t) at (1.5,-0.5) {$\mathcal{T}$};
    \draw (0) -- (1) -- (2) -- (qn) ; 

    \node [draw,circle,inner sep=2pt] (qn2) at (7.6,2) {};
    \node [above left] at (qn2) {$q_{new}$};

    \draw (qn) -- (qn2) ;

    \path[draw=black,line join=miter,line cap=butt,line width=0.800pt, fill=gray]
    (8,2) .. controls (8,4) and (10,6) ..
    (12,5) .. controls (14,4) and (14,4) ..
    (15,2) .. controls (15,0) and (14,0) ..
    (13,0) .. controls (11,1) and (8,1) ..
    (8,2) -- cycle;


    \node [draw,circle,inner sep=2pt,fill=white] (qrand) at (13,2) {};
    \node [below] at (qrand) {$q_{rand}$};

    \node at (10.5,4) {Obstacle};
    

    \draw [dashed,thin] (qn2) -- (qrand) ;



  \end{tikzpicture}

  \caption{One step of extension of the RRT algorithm. The algorithm tries to add the longest possible edge
  from $q_{near}$ towards $q_{rand}$, while avoiding collisions.} 
  \label{fig:rrt-extend}
\end{figure}

The equivalent random  extension on a constrained manifold $\manifold$, 
defined by the constraint function $f$,
starts from a valid configuration $q_{near} \in \manifold$, and extends the tree
towards a random configuration $q_{rand}$, while keeping the constraints
satisfied. Extension attempts orthogonal to $\manifold$ are useless,
as newly added edges have to be included  in $\manifold$. To extend in directions
that follow the directions of $\manifold$, we rely on the framework of 
Jacobian-based prioritized inverse kinematics. Algorithm~\ref{alg:constrained} presents
the adaptation of the classic extend function, and Fig.~\ref{fig:gikrrt} illustrates this
extension. The idea is to first project $q_{rand}$ on the tangent
space to $\manifold$  at $q_{near}$. Let us call the projected configuration $q_{rand}'$.
$q_{rand}'$ is obtained by one step of prioritized inverse kinematics optimization. Let 
$q_{rand}''$  be the result of a call to $\texttt{constraint-solver}(q_{rand}',f,\epsilon)$.  It is 
the projection
of $q_{rand}'$ on $\manifold$. Instead of extending the tree from $q_{near}$ towards 
$q_{rand}$, the algorithm tries to extend from $q_{near}$ towards 
$q_{rand}''$\footnote{This presentation attempts to give a precise idea of the algorithm, without 
  focusing on technical details. Readers interested in the actual implementation can
  refer to \url{https://github.com/laas/hpp-constrained} and 
  \url{https://github.com/laas/hpp-constrained-planner}, where the corresponding open-source 
  code is available.}. While extending the tree,
the configurations along the new edge are automatically projected onto $\manifold$. These projections 
are not very costly if the edge is close to the constrained manifold.

\begin{figure}[h]
\centering
\begin{minipage}[c]{0.6\linewidth}
\begin{tikzpicture}[y=0.55pt, x=0.55pt,yscale=-1, inner sep=0pt, outer sep=0pt]
\definecolor{dg}{rgb}{0,0.3,0}
\path[draw=black,line join=miter,line cap=butt,line width=0.800pt, fill=gray]
  (231.3249,143.2249) .. controls (178.0814,153.1889) and (178.5527,172.4247) ..
  (180.8173,200.8036) .. controls (183.2959,231.8645) and (195.6610,188.6038) ..
  (256.5787,230.0980) .. controls (295.8993,256.8813) and (346.4296,308.3911) ..
  (295.9747,178.5802) .. controls (275.5517,126.0356) and (304.8066,129.4735) ..
  (231.3249,143.2249) -- cycle;
\node at (230,180) {Obstacle};
\path[dashed,draw=dg,line join=miter,line cap=butt,line width=1.5pt]
  (88.8934,277.5752) .. controls (196.3490,276.5363) and (532.8532,213.7494) ..
(434.3656,81.6056) node [above = 0.1cm, color=dg, text width=1.8cm] {\small{Constrained manifold $\manifold$}};
\node [draw,circle,inner sep=2pt,fill = gray] (qn) at (97,277) {};
\node [above = 0.15cm] at (qn) {$q_{near}$};
\node [draw,circle,inner sep=2pt] (qr1) at (367,99) {};
\node [left = 0.2cm] at (qr1) {$q_{rand}$};
\draw [dashed,thin] (qn) -- (450,277);
\node [draw,circle,inner sep=2pt] (qr2) at (367,277) {};
\node [below right = 0.1cm] at (qr2) {$q_{rand}'$};
\node [draw,circle,inner sep=2pt,fill = gray] (qr3) at (345,225) {};
\node [above = 0.22cm] at (qr3) {$q_{rand}''$} ;
\draw [dashed,thin] (qr1) -- (qr2) -- (qr3);
\node [draw,circle,inner sep=2pt,fill = gray] (qnew) at (270,250) {};
\node [above = 0.1cm, left = 0.2cm] at (qnew) {$q_{new}$};
%\draw [thick] (qn) -- (qnew);

\end{tikzpicture}
\end{minipage}
\begin{minipage}[c]{0.3\linewidth}
\begin{tikzpicture}[x=0.61cm,y=0.61cm]
   \definecolor{dg}{rgb}{0,0.3,0}
      %Stack of tasks:
      \draw [color=black, thick,fill = white] (0,1) rectangle (2,2);
      \draw [color=black, thick,fill = white] (0,2) rectangle (2,3);
      \draw [color=black, thick,fill = white] (0,3) rectangle (2,5);
      \draw [color=black, thick,fill = white] (0,5) rectangle (2,6);
      \draw [color=black, thick,fill = white] (0,6) rectangle (5,7);
      \draw [color=black, thick,fill = white] (1,1) rectangle (5,6);
      \draw [thick] (1,1) -- (5,1) -- (5,6);
      \draw (1,2) -- (5,2) ;
      \node [text width = 5cm,text centered] at (2.5,6.5) {\large Stack
        of tasks};
      \begin{scriptsize}
        \node at (0.5,5.5) {1};
        \node at (0.5,4) {$\vdots$}; 
        \node at (0.5,2.5) {$n$};
        \node at (0.5,1.5) {$n$+1};

        \node [text width = 2cm,color=dg] at (3.2,4) {\small Constraints defining
          $\manifold$};
        \node [text width = 3cm,text centered] at (3,1.5)
              { Configuration task towards $q_{rand}$};    
      \end{scriptsize}


\end{tikzpicture}
\end{minipage}

\caption{One step of constrained extension, and the stack of tasks used
  to generate $q_{rand}'$ with a prioritized inverse kinematics solver, 
  starting from $q_{near}$:
  first, the constraints defining $\manifold$, and at a lower priority
  a configuration task towards $q_{rand}$.  $q_{rand}'$ is then projected onto
  $\manifold$, and a classic RRT extension tries to go as far as possible
  from $q_{near}$ towards $q_{rand}''$.}
\label{fig:gikrrt}
\end{figure}





\begin{algorithm}[h]
  \caption{Constrained-Extend($\mathcal{T},q_{near},q_{rand},f,\epsilon$)}
  \label{alg:constrained}
  \begin{algorithmic}
    \STATE {\color{red} // $I$ denotes the identity matrix.}
    \STATE $q_{rand}' \leftarrow q_{near} +   
    \left(I -  
    \left(\frac{\partial f}{\partial q}(q_{near})\right)^{+}
    \frac{\partial f}{\partial q}(q_{near})\right) (q_{rand} - q_{near})$
    \IF {$\texttt{constraint-solver}(q_{rand}',f,\epsilon) = q_{rand}''$} 
    \STATE RRT::Extend($\mathcal{T},q_{near},q_{rand}''$)
    \ENDIF
  \end{algorithmic}
\end{algorithm}







\subsection{Example}

We present in Fig.~\ref{fig:wb-shelves} an illustration of 
the use of randomized motion planning 
on complex manipulation problems. The humanoid robot HRP-2 faces shelves. It has to: (i) grasp
a ball lying on a shelf, (ii) put it on a higher shelf, (iii) come back to a natural
rest configuration. The statical balance manifold on which the planning takes place is
defined by tasks constraining the robot feet and CoM. The goal of the first problem

FIXME: what follows is not clear, rephrase to say that the hand
position is fixed and that it can rotate along the vertial axis.

is defined by a hand configuration task (3 positions and 2 orientations), and a gaze task
(the robot has to look at the ball). The goal of the second problem is defined by a 
different hand configuration and the gaze task.
Finally, the goal of the third problem is the rest configuration.

For the two reaching motions, we generate 8 random goal configurations (Section~\ref{sec:goal-sampling}).

Extension 1 presents a video of this motion after an optimization step.

\begin{figure}[h]
\centering
\includegraphics[width=0.24\linewidth]{pics/wb-shelves/1.jpg}
\includegraphics[width=0.24\linewidth]{pics/wb-shelves/2.jpg}
\includegraphics[width=0.24\linewidth]{pics/wb-shelves/3.jpg}
\includegraphics[width=0.24\linewidth]{pics/wb-shelves/4.jpg}
\\
\vskip 0.08cm
\includegraphics[width=0.24\linewidth]{pics/wb-shelves/5.jpg}
\includegraphics[width=0.24\linewidth]{pics/wb-shelves/6.jpg}
\includegraphics[width=0.24\linewidth]{pics/wb-shelves/7.jpg}
\includegraphics[width=0.24\linewidth]{pics/wb-shelves/8.jpg}



\caption{HRP-2 grabs a ball on a shelf, puts it on another shelf, and comes back to 
  a rest position. Static balance constraints are enforced along the path, and 
  the intermediary goals consisting in grasping and displacing the ball are defined
  implicitly as inverse kinematics tasks.}
\label{fig:wb-shelves}
\end{figure}

We have run this set of motion planning problems 20 times. The results are compiled in Table~\ref{table:reaching}.
\begin{table}
\begin{tabular}{l|r|r|r|r|}
\cline{2-5}
& min & max & average & average \\ 
&&&& per problem \\
\hline
\multicolumn{1}{|l|}{number of nodes} & 43.00 & 481.00 & 102.70 \\
\cline{1-4}
\multicolumn{1}{|l|}{goal generation time (s)} & 1.00 & 1.56 & 1.22\\
\hline
\multicolumn{1}{|l|}{planning time (s)} & 67.36 & 376.84 & 134.28 & 44.76\\
\hline
\end{tabular}
\caption {\textbf{Experimental results on 20 runs: Each run consists
    of 3 motion planning problems and 2 goal generations for the three
    phases. Time is expressed in seconds.}}
\label{table:reaching}
\end{table}

Among all calls to \texttt{constraint-solver}, the average number of iterations is 6.5 and the success rate is above 95 percent.

\section{From Statically Balanced Paths to Dynamic Walk Trajectories}
\label{sec:wb-step}

The previous section has presented a simple algorithm that solves manipulation planning
problems on a given constraint manifold of $\mathcal{C}$. 

If we use this algorithm with static 
balance constraints without fixing globally the robot foot positions, it generates 
statically balanced paths for a robot sliding on the ground. Fig~\ref{fig:sliding} shows
an example of a whole-body collision-free path for a robot passing between two chairs.
Such paths are physically unfeasible. They are, however, easier to generate than feasible
dynamic trajectories because only geometric constraints are considered at planning time.

\begin{figure}[h]
  \centering

  \includegraphics[width=0.24\linewidth]{pics/chairs/sliding-perspective-1.png}
  \includegraphics[width=0.24\linewidth]{pics/chairs/sliding-perspective-2.png}
  \includegraphics[width=0.24\linewidth]{pics/chairs/sliding-perspective-3.png}
  \includegraphics[width=0.24\linewidth]{pics/chairs/sliding-perspective-4.png}


  \caption{Collision-free  statically balanced path  for a  humanoid  robot  sliding on  the
    ground.}
  \label{fig:sliding}
\end{figure}



This section presents a \textit{constructive} proof that any such statically balanced, 
collision-free path for a legged robot sliding
on the ground can be approximated by a  dynamically balanced, collision-free walk trajectory.
The proof is based on ideas from control theory, in particular small-space 
controllability. It also uses the fact that balance criteria for dynamic walking are different
from the ones for static balance. An important point is that our result and method do not hold
for a biped robot that walks in a quasi-static way. 

Section~\ref{sec:ssc} recalls the definition of small-space controllability and its
use in motion planning. Section~\ref{sec:humanoid-ssc} proves that a
dynamically walking legged robot is small-space controllable, while a quasi-statically
walking legged robot is not. Section~\ref{sec:ssc-application} shows how this property is used to
approximate collision-free statically balanced paths by dynamic walking trajectories.


\subsection{Small-Space Controllability}
\label{sec:ssc} 

A  robotic system  is  controllable  if  for any two  configurations
$q_1$ and $q_2$,  there exists  a
trajectory  going  from  $q_1$ to  $q_2$.  It  is  
\textit{small-space  controllable} if for all configurations  $q$, 
for all $\epsilon >0$, there
exists $\eta >0$ such that all the configurations contained in the ball of center
$q$ and radius $\eta$ are reachable by trajectories included in the
ball of center $q$ and radius $\epsilon$. Fig.~\ref{fig:ssc1} shows an illustration
of this property.

\begin{figure}[h]
  \centering
  \input{stc1.tex}

  \caption{The small-space controllability local property:  any configuration $q'$ 
    at a distance less than
    $\eta$ is reachable from $q$ by an admissible trajectory included in
    a ball of size $\epsilon$.}
  \label{fig:ssc1}
\end{figure}

The main  consequence of  this property  
in  motion planning  is the following theorem, that shows how planning for
dynamic systems is reduced to geometric planning
thanks to the small-space controllability property:

\begin{theorem}
  \label{thm:ssc}
  Any collision-free path of a small-space controllable system can be approximated
  by a sequence of both collision-free and admissible trajectories. Thus, small-space 
  controllability reduces trajectory planning problems to geometric path planning problems.
\end{theorem}

Fig. \ref{fig:ssc2} shows an example of collision-free 
path approximation by admissible collision-free sub-trajectories. The convergence 
of this algorithm is guaranteed by the small-space
controllability property.

\begin{figure}[h]
  \centering

  \input{stc2.tex}

  \caption{Small-space controllability in motion planning. 
    A collision-free path from
    $q_1$ to $q_2$ is approximated by collision-free and admissible
    trajectories by using the local property.
  }
  \label{fig:ssc2}
\end{figure}

This result has been long known and used in motion planning, in particular
for non-holonomic systems. A detailed proof can be found in
\cite{taix-94}. We will present a sketch of the proof to give an intuition about the 
corresponding algorithm.

\begin{proof}[Proof of Theorem \ref{thm:ssc}]
  Let $\mathcal{C}$ be the configuration space of a small-space controllable robot, and 
  $\mathcal{C}_{free} \subset \mathcal{C}$ the set of collision-free configurations. We
  consider in-contact configurations as colliding, so $\mathcal{C}_{free}$ is an open set.
  Let $\tau : [0,1] \rightarrow \mathcal{C}_{free}$ be a collision-free path. Thus for all $x \in [0,1]$,
  $\tau(x) \in \mathcal{C}_{free}$, there exists $\epsilon_x$ such that the open ball 
  $B(\tau(x),\epsilon_x)$ of center $\tau(x)$ and radius $\epsilon_x$ is included in 
  $\mathcal{C}_{free}$. The small-space controllability property states that for all $x$,
  there exists $\eta_x > 0$ such that every configuration $q \in B(\tau(x),\eta_x)$ is reachable 
  from $\tau(x)$ by a trajectory included in $B(\tau(x),\epsilon_x)$.

  The set of open balls $\left( B(\tau(x),\eta_x) \right)_{x\in [0,1]}$ forms an open cover
  of $\tau([0,1])$ which is compact. \textbf{The Heine-Borel theorem \cite{fitzpatrick2006advanced} states that there exists a
  finite subcover $\left( B(\tau(x_i),\eta_{x_i}) \right)_{i\in \{ 1,\dots ,n \}}$ of $\tau([0,1])$}. To this
  finite subcover corresponds a finite number of feasible trajectories, going from $\tau(0)$ to  
  $\tau(1)$, included in the union of 
  $\left( B(\tau(x_i),\epsilon_{x_i}) \right)_{i\in \{ 1,\dots ,n \}}$, and thus in 
  $\mathcal{C}_{free}$. This concludes the proof.
\end{proof}

\subsubsection{Small-Time \textit{versus} Small-Space Controllability}
In the control theory literature, the property used is usually \textit{small-time controllability}, 
which states that for  all configurations  $q$, for  all times
$T>0$, the set of configurations accessible from $q$ in time less than
$T$ forms a  neighborhood of $q$. When accelerations and velocities are bounded,
small-time controllability implies small-space controllability. This is why 
a lot of motion planning previous work only refers to the sufficient small-time controllability
property. However, the reciprocate is not necessarily true:  a system can be 
small-space controllable and
not small-time, if the trajectories generated by its controller are arbitrarily long.
The important property, regarding
motion planning application, is small-space controllability, as 
Theorem~\ref{thm:ssc} shows. In the following, we show that legged robots
are small-space controllable, but  not that they are small-time controllable.
In fact, the  control method that we present does not follow the small-time controllability
property. For the sake of clarity, we have chosen to make the distinction between these
two controllability properties.



\subsection{Dynamic Walking Makes Humanoid Robots Small-Space Controllable}
\label{sec:humanoid-ssc}

This section  discusses a walking robot small-space controllability. To clarify
the presentation, we consider a simplified model of a legged robot consisting of two feet
of zero mass and a point mass free to move in three dimensions.
We do not consider 
the kinematic chains between the feet and the mass. The robot is walking on a flat terrain,
and the feet are assumed to have a positive surface. For our presentation, it is not 
necessary to consider the foot height, so the configuration space of the robot is:
\[
\mathcal{C} = SE(2) \times SE(2) \times \mathbb{R}^3
\]
It is of dimension 9.


The balanced walking conditions for a quasi-static walking robot are that the point
mass, or CoM, should always be over the support polygon (the convex hull of the two feet), and 
one foot can move iff the CoM is over the other foot. Similarly, the walking
conditions for a dynamic walking robot are that the ZMP should
always be in the robot support polygon, and one foot can move iff the ZMP is over the other 
foot. For a precise description of dynamically balanced walking conditions, the reader can refer
to \cite{wieber2002}. Under these assumptions, the following result holds:

\begin{theorem}
\label{thm:humanoid-ssc}
A quasi-statically walking robot is not small-space controllable. A dynamically walking robot is.
\end{theorem}

\begin{proof}[Proof of Theorem \ref{thm:humanoid-ssc}]

The first claim is straightforward. Let the robot be in a configuration $q$ where the two
feet are separated by a positive distance. Let  $L>0$ be the positive horizontal distance
between the CoM and the left foot (if the CoM is over the left foot, we can consider similarly 
the right foot). For all $\epsilon < L$, any valid trajectory starting from $q$, included in
the ball of center $q$ and radius $\epsilon$, is such that the CoM is never over the left foot.
Given the quasi-static walking conditions, the right foot of the robot is fixed along 
the trajectory. Thus, the set of accessible configurations from $q$ by staying inside 
$B(q,\epsilon)$ does not form a neighborhood of $q$, since it does not include any configuration
where the right foot has moved. This shows that the robot is not small-space controllable.

\bigskip

Let us now consider a dynamically walking robot. Starting from any valid static configuration, 
the CoM can move vertically without affecting balance, so there is no need to 
consider this degree of freedom in the following. If the CoM is not over the edge of the support
polygon, it is possible to move it in a quasi-static way inside a neighborhood of its current position that projects itself over the support polygon.
It is thus sufficient and necessary to prove that for all $\epsilon >0$, it is possible to move
the feet while keeping the CoM inside a neighborhood of size $\epsilon$. Let such $\epsilon >0$
be arbitrarily fixed.


The model of a walking robot with a point
mass at a fixed height is known in the literature as the cart-table model \cite{kajita2003biped}.
The equations  giving  the   ZMP  horizontal  coordinates  $(p_x,p_y)$  as
functions  of CoM  horizontal coordinates $(x,y)$  in the  cart-table  model were
presented in \cite{kajita2003biped}:
\begin{equation}
\label{eq:walk-zmp}
\left(
\begin{array}{c}
p_x\\ p_y
\end{array}
\right) = \displaystyle \left(
\begin{array}{c}
x - \frac{z_c}{g} \ddot{x}\\ y - \frac{z_c}{g} \ddot{y}
\end{array}
\right)
\end{equation}
where $z_c$ is  the constant height of the CoM and  $g$ is the gravity
constant.    In    the    following    we    will    note    $\omega_0
=\sqrt{\frac{g}{z_c}}$.

Without loss of generality, let us assume that the robot is in a configuration
in which the CoM is at the horizontal position $(0,0)$, the foot centers  are 
aligned with the $y$-axis and the horizontal distance between the CoM and either of the foot centers
is $L$. To achieve dynamically balanced walking, we aim at making
$p_y(t)$ oscillate  between $-L$ and $L$. To move the ZMP  under a
given foot, only  the $y$ coordinate of the CoM  is of interest. Thus,
we will keep the $x$ coordinates  of the CoM and ZMP constant equal to
$0$. By hypothesis, the feet have a positive surface,
let $l>0$ be such that the length of the section of a foot along the 
$y$-axis is greater than $l$. Fig.~\ref{fig:simple-humanoid} summarizes the notations used
in the following.

\begin{figure}[h]
  \centering
  \input{humanoid.tex}

  \caption{Simplified model of a legged robot. The CoM is at $(0,0,z_c)$, the two feet 
    are flat on the ground, aligned with the $y$-axis, at a horizontal distance $L$ 
    from the CoM.}
  \label{fig:simple-humanoid}
\end{figure}


The idea of this proof is to use the form of Eq. (\ref{eq:walk-zmp}) to
apply a  scaling factor between  the amplitude of the  oscillations of
the CoM and of the ZMP. The faster the CoM oscillates, the bigger is the amplitude
of the ZMP oscillations. Following is a formalization of this  idea.

For $\omega >0$, assuming the CoM follows the trajectory
$y(t) = \epsilon \sin(\omega t)$,  Eq. (\ref{eq:walk-zmp}) gives:
\[
p_y(t) =
(1+\left(\frac{\omega}{\omega_0}\right)^2)\epsilon\sin(\omega t)
\]

The
amplitude  of  the oscillations  of  $y$  is  multiplied by  a  factor
$(1+\left(\frac{\omega}{\omega_0}\right)^2)$.  Choosing  $\omega =
\omega_0 \sqrt{\frac{L}{\epsilon} -1}$ makes  $p_y$ oscillate between $-L$
and    $L$, while $y$ oscillates between $-\epsilon$ and $\epsilon$.   
At    time   $t_l^{(n)}    =    n\frac{2\pi}{\omega}   +
\frac{\pi/2}{\omega}$, the  ZMP is located  at the center of  the left
foot,  the robot  can move  its right  foot and  at time  $t_r^{(n)} =
n\frac{2\pi}{\omega}  + \frac{3\pi/2}{\omega}$ the  ZMP is  located at
the center of the right foot, the robot can move its left foot.

Starting from a static configuration at time $(t=0)$, we cannot apply
directly  a  command  $y(t)  =  \epsilon \sin(\omega  t)$  because  it
generates  a discontinuity  in the  speed of  the CoM  at time $(t=0)$. To
overcome this  discontinuity, we go through a  transient state between
$(t=0)$ and  $(t=T)$ for some  $T >0$. Let  $f:[0,T] \rightarrow
[0,1]$  be an  increasing function of class $C^\infty$  such  that  $f(0)  =  0$,
$\dot{f}(0) = 0$, $f(T) =  1$, $\dot{f}(T) = 0$ and $\ddot{f}(T)
=  0$.  We can explicitly  construct  such  an $f$   with  a
spline of degree  4.   We   also   request   that   for  all   $t   \in   [0,T]$,
$|2\epsilon\dot{f}(t)\frac{\omega}{\omega_0^2}|   \leq  \frac{l}{4}$
and   $|\epsilon\ddot{f}(t)/\omega_0^2|  \leq   \frac{l}{4}$.  These
inequalities  will be  used  to bound  the  trajectory of  the  ZMP. We  can
guarantee them by  choosing $T$ large enough. Let  us now consider the
following CoM motion:

\[
y(t) = \left\{
\begin{array}{ll}
f(t)\epsilon\sin(\omega t) 
& \text{if } t\in [0,T]
\\ 
\epsilon\sin(\omega t) 
& \text{if } t \geq T \end{array}
\right.
\]

One can  check that $y$  is of class $C^2$ over  $\mathbb{R}_+$, and
that $\dot{f}(0) = 0$. When $t\geq T$, the robot is in the permanent
state described above  and can successively move either of its 
feet  inside small neighborhoods.
The  last point to check
is that for $t \in  [0,T]$ $p_y(t)$ stays inside the support polygon
of the robot. The calculation of the successive derivatives of $y$ gives:

\[
\begin{array}{cl}
p_y(t) = &  f(t) \epsilon (1 + \left(\frac{\omega}{\omega_0}\right)^2)
\sin (\omega  t) \\ &  + 2\epsilon \dot{f}(t)\frac{\omega}{\omega_0^2}
\cos  (\omega t)  \\ &  +  \frac{\epsilon}{\omega_0^2}\ddot{f}(t) \sin
(\omega t)
\end{array}
\]



\begin{figure}
\centering
\input{fig-zmp-inplace.tex}

\caption{CoM motion (in plain red) along $y$ axis.  The CoM stays in the interval
  $[-\epsilon,\epsilon]$ while during  permanent state ($t \geq T$),
  the ZMP (dashed blue) oscillates between the centers of the feet, which allows
  in-place walk.}
\label{fig:zmp-inplace}
\end{figure}

For    all     $t    \in    [0,T]$,    $f(t)     \epsilon    (1    +
\frac{\omega}{\omega_0}^2)  \sin  (\omega t)$  lies  between $-L$  and
$L$. The bounds on the derivatives of $f$ guarantee that $p_y(t)$ lies
between  $-L- l/2$ and  $L+ l/2$,  which means  that the  ZMP stays
inside  the  support  polygon.  Fig.  \ref{fig:zmp-inplace}  shows  an
example  of CoM  motion  on the  $y$  axis and  the corresponding  ZMP
motion. Once in permanent in-place walking state, the robot can come back
to  a static  state by  applying a  symmetric transient  state  used to
decrease  gradually  the amplitude  of  the  oscillations  of the  CoM
without  generating a  discontinuity in  the first  derivative  of the
command.


We have thus exhibited a continuous control scheme that allows to move any of the feet
in any direction, while keeping the CoM inside an arbitrarily small neighborhood. This concludes
the proof.
\end{proof}


\subsubsection{Remarks}
\paragraph{Generalization to a complete model:} More work is needed to generalize 
the previous proof to any legged robot model. First, because we use a model with
a point mass, we did not have to consider the angular momentum of the robot
around the CoM, while it accounts for dynamic balance. Moreover, when considering
an actual kinematic and dynamic model,
the positions of feet and CoM are not controlled DoFs, but inputs 
for inverse kinematic tasks. Continuity and regularity results about the robot
controller -- i.e. how much the configuration changes when the input of an inverse
kinematics task changes--, would be needed to generalize the proof. We have not
proven such properties for the inverse kinematics controller we use. 
The  proof presented above still gives the intuition for the
algorithm presented in the following.


\paragraph{Use of ZMP preview controller:} The control strategy presented in the  
previous proof may
generate very  long trajectories, because  of the transient  states at
the beginning and end of the locomotion. In the actual implementation,
we have chosen  to generate  CoM motions with  a ZMP preview  controller, as
presented in \cite{kajita2003biped}.  We  have observed experimentally that the
amplitude of  CoM trajectories decreases  when the frequency  of steps
increases. Our current ZMP preview controller relies on the cart-table model approximation.
To make this approximation valid, we fix the height of the robot CoM during walk,
as well as the vertical orientation of the robot waist. These geometric constraints 
are also applied when planning statically balanced paths, to ensure that the paths
can be approximated by dynamic walk trajectories. Note that this is
due to our current  ZMP preview controller implementation, and does not affect
the generality of the small-space controllability result presented above.

\textbf{Relying on the cart-table model approximation means that the
  angular momentum induced by arm movements for instance can lead to
  non dynamically balanced walking motion. We thus implement the ZMP
  filtering stage proposed in \cite{kajita2003biped} to compute the
  exact ZMP and take into account the full dynamics of the robot and
  generate feasible trajectories.}

\paragraph{Speed of CoM:} The theoretical result presented in this section implies
that any collision-free path can be approximated by a sequence of admissible 
and collision-free trajectories. However, the theorem depends on a control law
that generates trajectories with unbounded velocities for the CoM, when the input
path is close to obstacles. The humanoid robot
hardware may be a limitation to such trajectories. To prevent the generated CoM 
oscillations from being too fast, one has to require that the statically balanced 
path is included
inside an $\epsilon$-radius tube of the free space, where $\epsilon$ depends on the
physical capacities of the robot.




\subsection{Application: Dynamic Approximation of a Statically Balanced Sliding Path}
\label{sec:ssc-application}


The  algorithm   that  animates  a  statically  balanced   path  into  a
dynamically balanced  walk trajectory has been inspired  by the previous
small-space controllability  proof.
Given a statically  balanced path $p$ respecting the cart-table model approximation constraints,
we  start  by placing  footprints  corresponding  to  the nominal  walk
pattern  of the  robot. Given the footprints, we  compute a ZMP trajectory, 
and a preview controller outputs  a corresponding CoM trajectory. 
The stack of tasks applied to
the robot to generate a dynamic walk motion is -- in decreasing priority order:

\begin{enumerate}

\item Positions and orientations of  feet,

\item Horizontal position of the CoM,

\item Height of the CoM,

\item Verticality of the waist,

\item Configuration task towards corresponding
  configuration  in $p$.

\end{enumerate}

Tasks (1)  and (2) generate a  dynamically balanced motion  by using the
simplified cart-table model  and the ZMP criterion. Tasks  (3) and (4)
ensure that the  resulting motion is well described  by the cart-table
model. Task (5)  is used to approximate $p$ as  well as possible given
the walk parameters.

Because it comes at the  lowest priority, task (5) is not necessarily
fulfilled in  the resulting trajectory. Hence,  collisions may appear
when animating $p$, if the resulting trajectory diverges too much from
the initial sliding  path. If so, it is  necessary to approximate more
closely $p$  by a walk  trajectory.  To do  so, we use  the small-space
controllability  property   of  the  system  shown   in  the  previous
section. The way  we use this property is  inspired by similar results
in non-holonomic mobile robot control presented in \cite{taix-94}.

If the animated  trajectory collides with the environment,  we cut the
initial  path   $p$  into  two   sub-paths,  that  we  try   to  animate
recursively. When the  paths to animate are too  short for the robot
nominal  walk parameters, we  accelerate the  steps, and  decrease the
maximum height of  the moving foot. As shown  in previous section, the
walk trajectory  corresponding to  smaller and faster  steps converges
toward the  sliding path.  Algorithm ~\ref{alg:walk} shows pseudo-code
that takes  a sliding path $p$  as input and  returns a collision-free
walk trajectory\footnote{The actual implementation of this algorithm is
part of an open-source package, available at
\url{https://github.com/laas/hpp-wholebody-step-planner}.}.

\begin{algorithm}[h]
\caption{FindDynamicTrajectory(Path $p$)}
\label{alg:walk}
\begin{algorithmic}
\STATE $Footprints \leftarrow \text{ComputeFootprints}(p)$

\STATE $StackOfTasks$.initialize()

\STATE $StackOfTasks$.addFootprintTask($Footprints$)

\STATE $StackOfTasks$.addWaistTask()

\STATE $StackOfTasks$.addConfigurationTask($p$)

\STATE $DynamicTrajectory \leftarrow \text{Animate}(StackOfTasks)$

\IF{(CheckForCollisions($DynamicTrajectory$) = Colliding)}

\STATE $(p_1,p_2) \leftarrow \text{CutInHalf}(p)$

\STATE $DT_1 \leftarrow \text{FindDynamicTrajectory}(p_1)$

\STATE $DT_2 \leftarrow \text{FindDynamicTrajectory}(p_2)$

\RETURN $\text{Concatenate}(DT_1,DT_2)$

\ELSE

\RETURN $DynamicTrajectory$

\ENDIF
\end{algorithmic}
\end{algorithm}





\section{Experimental Results}

\label{sec:exp}

\textbf{The motion planning algorithms presented in this paper have been
implemented using KineoWorks\texttrademark \cite{laumond2006kcs}. The
planning times have been measured on an Intel Core~2~Duo 2.13~GHz PC
with 2~GB of RAM. Evaluation of the randomized algorithm has been
conducted by executing 500 trials on each scenario using two flavors of
RRT: the classic RRT and IPP-RRT \cite{FERR04A}. We present the
results in Fig. \ref{fig:rrt-it}, \ref{fig:rrt-t}, \ref{fig:rrt-n}, as
well as in Extension 4 for the raw data.}

\subsection{Passing between two chairs}

The environment shown in Fig. \ref{fig:couv} and \ref{fig:sliding} was presented
in \cite{el2011path}. There, the motion planning problem is solved with a bounding
box method, leading the robot to walk sideways between the two chairs.
Our method generates a locomotion  trajectory in which the robot walks
forward, which may be required if the robot has to use vision during
locomotion. The first planning stage  requires 29.6~s
on  average.   The  animation  of   the  sliding  path   presented  in
Fig.   \ref{fig:sliding}   uses  66.5~s  of  computation   time.


\begin{figure}[h!]
\centering
\includegraphics[width=0.7\linewidth]{pics/chairs/waist-trajectory.png}

\caption{Horizontal trajectory of the robot CoM during
  locomotion. When the robot is close to obstacles, the amplitude of
  the oscillations decreases.}
\label{fig:chairs-waist}
\end{figure}



Fig.  \ref{fig:chairs-waist} shows  the horizontal  trajectory  of the
robot CoM  during  locomotion. The amplitude of the oscillations  decreases when passing
between the  chairs.  This motion has  been validated on  a real HRP-2
platform. Extension 2 shows a video of the experiment.


\subsection{Walking among floating obstacles}

\begin{figure}[h!]

\centering

\includegraphics[width=0.24\linewidth]{pics/objects-cloud/perspective-1.png}
\includegraphics[width=0.24\linewidth]{pics/objects-cloud/perspective-2.png}
\includegraphics[width=0.24\linewidth]{pics/objects-cloud/perspective-3.png}
\includegraphics[width=0.24\linewidth]{pics/objects-cloud/perspective-4.png}
\\ 
\vskip 0.08cm
\includegraphics[width=0.24\linewidth]{pics/objects-cloud/perspective-5.png}
\includegraphics[width=0.24\linewidth]{pics/objects-cloud/perspective-6.png}
\includegraphics[width=0.24\linewidth]{pics/objects-cloud/perspective-7.png}
\includegraphics[width=0.24\linewidth]{pics/objects-cloud/perspective-8.png}

\caption{Solution path for a cluttered environment, the robot walks
  among floating obstacles.}
\label{fig:cluttered}
\end{figure}

In the environment shown in Fig. \ref{fig:cluttered}, the robot
has to find a way among floating obstacles. In this
environment neither bounding box nor footstep planning strategies
could find a collision-free walk trajectory.
The first planning stage requires
184.3~s on average, and the animation of the trajectory presented in 
Fig.~\ref{fig:cluttered} uses 339.5~s of computation time. Fig.~\ref{fig:cluttered-waist} 
shows the robot CoM trajectory during locomotion.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.7\linewidth]{pics/objects-cloud/waist-trajectory.png}

  \caption{Horizontal trajectory of the robot CoM during
    locomotion.}
  \label{fig:cluttered-waist} 
\end{figure}


\subsection{'Put the ball on a shelf'}

In the problem shown in Fig. \ref{fig:shelf} the robot has to put a ball on a
shelf, in a constrained apartment environment. The final configuration is defined 
implicitly as a desired hand position. We have generated automatically goal configurations 
solving the task, as described in Section~\ref{sec:wb} . Then, we have
applied our planner to generate a whole-body walking motion that solves the hand reaching
task. 

The solution sliding path is constrained between the table on the right and the lamp
on the left. This passage is too narrow for the robot nominal walk parameters. 
When executing the walk motion resulting from our algorithm, the robot left hand
is only a few centimeters away from the lamp.

Fig.~\ref{fig:shelf} shows the resulting walk motion and Fig.~\ref{fig:shelf-waist} 
shows the robot CoM trajectory during locomotion. Extension 3 presents a 
comprehensive video of this problem, including the motion execution on
the real robot HRP-2 on stage. Fig.~\ref{fig:shelf-cdf} shows some snapshots 
taken from Extension 3.


\begin{figure}[h]
\centering
\includegraphics[width=0.24\linewidth]{pics/shelves/trajectory-1.png}
\includegraphics[width=0.24\linewidth]{pics/shelves/trajectory-2.png}
\includegraphics[width=0.24\linewidth]{pics/shelves/trajectory-3.png}
\includegraphics[width=0.24\linewidth]{pics/shelves/trajectory-4.png}
\\ 
\vskip 0.1cm
\includegraphics[width=0.24\linewidth]{pics/shelves/trajectory-5.png}
\includegraphics[width=0.24\linewidth]{pics/shelves/trajectory-6.png}
\includegraphics[width=0.24\linewidth]{pics/shelves/trajectory-7.png}
\includegraphics[width=0.24\linewidth]{pics/shelves/trajectory-8.png}

\caption{Solution path for a hand reaching problem in an
  apartment. The goal is implicitly defined as an inverse kinematics
  task.} 
\label{fig:shelf}
\end{figure}




\begin{figure}[h]
\centering

\includegraphics[width=0.4\linewidth]{pics/shelves/waist-trajectory.png}


\caption{Horizontal trajectory of the robot CoM during
    locomotion.}
\label{fig:shelf-waist}
\end{figure}

\begin{figure}[h]
\centering

\includegraphics[width=0.19\linewidth]{pics/shelves-cdf/1.jpg}
\includegraphics[width=0.19\linewidth]{pics/shelves-cdf/2.jpg}
\includegraphics[width=0.19\linewidth]{pics/shelves-cdf/3.jpg}
\includegraphics[width=0.19\linewidth]{pics/shelves-cdf/4.jpg}
\includegraphics[width=0.19\linewidth]{pics/shelves-cdf/5.jpg}

\caption{Execution of the walking trajectory by HRP-2 on stage. The robot first goes
  to the shelves to release the ball, then comes back to a rest position.}

\label{fig:shelf-cdf}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=0.8\linewidth]{plots/rrt-it.eps}
\caption{Number of RRT iterations $it$ for the floating objects and the
  shelf scenarios, using two variants of RRT. Mean $\overline{it}$,
  standard deviation $\sigma_{it}$, minimum and maximum values are
  represented.}
\label{fig:rrt-it}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=0.8\linewidth]{plots/rrt-t.eps}
\caption{RRT computation time $t$ for the floating objects and the shelf
  scenarios, using two variants of RRT. Mean $\overline{t}$, standard
  deviation $\sigma_{t}$, minimum and maximum values are represented.}
\label{fig:rrt-t}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=0.8\linewidth]{plots/rrt-n.eps}
\caption{Number of tree nodes $n$ for the floating objects and the
  shelf scenarios, using two variants of RRT. Mean $\overline{n}$,
  standard deviation $\sigma_{n}$, minimum and maximum values are
  represented.}
\label{fig:rrt-n}
\end{figure}

\section{Limits and Discussions}
\label{sec:limits}

This section lists several limitations of the current methods, and discusses
potential future work to overcome them.


\subsection{Stepping over obstacles}

Because of the kinematic constraints we apply at the planning stage, we are not
able yet to plan motions where the robot steps over obstacles, while this is an 
important feature of humanoid robots. Nevertheless, because we compute collision queries on
an exact model of the robot, our method is able to generate paths where obstacles
pass between the feet of the robot.
In future work, we plan to develop mixed
methods, where collision avoidance at the leg level can be solved by footstep
planning techniques, while whole-body collision-avoidance can be solved by the
algorithm presented in this paper.

\subsection{Environment representation}

\textbf{The presented experiment setup assumes perfect knowledge of
  the environment. This can be guaranteed during experiments by using
  calibrated objects and motion capture systems. This indeed allows us
  to focus on complex motion planning problems. The perception
  problem, interesting as it is, is thus completely decoupled from the
  planning problem in our presentation.}

\textbf{The constrained motion planner and the small-space
  controllability property can luckily still be used with different
  environment representations that might more suited with perception
  systems and their inherent measurement errors, using for instance
  point clouds. In the future, we would like to achieve dynamic walk
  planning using a Kinect sensor that would be mounted on the humanoid
  robot. This would relax the a priori environment knowledge
  constraint and bring us one step closer to reactive planning in
  unknown environments.}

\subsection{Trajectory following}

The presented setup also assumes perfect execution of the plan. It can
be critical here, since non-nominal stepping may cause the robot to
drift away from the planned trajectory. Future experiments will
include trajectory following during plan execution.

\section{Conclusion}

In this paper, we have presented a simple algorithm for constrained motion planning
and used it within a novel, well-grounded strategy for humanoid whole-body
manipulation planning including locomotion. The locomotion algorithm is based on a formal
small-space controllability property of humanoid robots. An important point is that
this strategy only holds for dynamic walking robots, and not for quasi-static walking ones.
We have used our motion planner on different challenging examples, and validated the
generated motions on a real platform. We have discussed the limits and potential extensions
of our method, and we plan to address them in future work.

\section{Acknowledgments}

This work was supported by the French FUI Project ROMEO and the European Project ECHORD-231143. The authors would like to thank Thomas Moulard and Olivier Stasse for their valuable help during experiments.


\bibliographystyle{agsm}   


\bibliography{bibli}



\end{document}
